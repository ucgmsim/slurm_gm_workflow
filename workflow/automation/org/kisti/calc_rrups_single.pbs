#!/bin/bash
# script version: pbs
#
# must be run with qsub -v REL=[realizationDirectory],MGMT_DB_LOC=[managementDBLocation] -V calc_rrups_single.pbs
# Please modify this file as needed, this is just a sample
#PBS -N calc_rrups_single
#PBS -V
#PBS -q normal
#PBS -A inhouse
#PBS -l select=1:ncpus=64
#PBS -l walltime=00:10:00
#PBS -W sandbox=PRIVATE

export PBS_JOB_ID="${PBS_JOBID/.pbs/}"
export SLURM_CPUS_PER_TASK=$(qstat $SLURM_JOB_ID -f | grep "used.ncpus" | cut -d"=" -f2 | bc)
export SLURM_NNODES=$(qstat $SLURM_JOB_ID -f | grep "List.nodect" | cut -d"=" -f2 | bc)

JOB_LOG_DIR=$REL_LOC/ch_log/json_log
mkdir -p ${JOB_LOG_DIR}
query_cmd="qstat -f -F json -x ${PBS_JOBID} >> ${JOB_LOG_DIR}/${PBS_JOBID}.json"
eval " ${query_cmd}"

function getFromYaml {
    echo $(python -c "from workflow.automation.sim_params import load_sim_params; print(load_sim_params('$1').$2)")
}
export IMPATH=${gmsim}/IM_calculation/IM_calculation/scripts
export PYTHONPATH=$gmsim/qcore:/${PYTHONPATH}:${IMPATH}

script_start=`date`
echo "script started running at: $script_start"
runtime_fmt="%Y-%m-%d_%H:%M:%S"
timestamp=`date +%Y%m%d_%H%M%S`
## qsub supply the following variables with -v option, exit if not set
echo REL:${REL:?REL not set}
echo MGMT_DB_LOC:${MGMT_DB_LOC:?MGMT_DB_LOC not set}

REL_NAME=`basename $REL`
REL_YAML=$(python -c "from qcore.simulation_structure import get_sim_params_yaml_path; print(get_sim_params_yaml_path('${REL}'))")

SRF_FILE=$(getFromYaml ${REL_YAML} srf_file)
# Get median srf file
SRF_FILE=${SRF_FILE//_REL??/}
STATION_FILE=$(getFromYaml ${REL_YAML} stat_file)
FD=$(getFromYaml ${REL_YAML} FD_STATLIST)

OUT_FILE=$(python -c "from qcore.simulation_structure import get_rrup_path; print(get_rrup_path('${MGMT_DB_LOC}', '${REL}'))")
OUT_DIR=`dirname $OUT_FILE`
mkdir -p $OUT_DIR

start_time=`date +${runtime_fmt}`
if [[ ! -f ${OUT_FILE} ]]
then
    # Create the output folder if needed
    echo ___calculating rrups___


    python $gmsim/workflow/workflow/automation/execution_scripts/add_to_mgmt_queue.py $MGMT_DB_LOC/mgmt_db_queue $REL_NAME rrup running $PBS_JOB_ID --start_time "$start_time" --nodes $SLURM_NNODES --cores $SLURM_CPUS_PER_TASK --wct 00:10:00

    time python ${IMPATH}/calculate_rrups_single.py -fd ${FD} -o ${OUT_FILE} ${STATION_FILE} ${SRF_FILE}
else
    echo "rrup file already present: ${OUT_FILE}"
    echo "Checking that there are enough rrups in it"
fi
end_time=`date +${runtime_fmt}`

if [[ -f ${OUT_FILE} ]]
then
    if [[ $(wc -l < ${OUT_FILE}) == $(( $(wc -l < ${FD}) + 1)) ]]
    then
        python $gmsim/workflow/workflow/automation/execution_scripts/add_to_mgmt_queue.py $MGMT_DB_LOC/mgmt_db_queue $REL_NAME rrup completed $PBS_JOB_ID --end_time "$end_time"
    else
        res="Not enough rrups for the station file"
    fi
else
    res="rrup file does not exist"
fi

if [[ -n ${res} ]]
then
    python $gmsim/workflow/workflow/automation/execution_scripts/add_to_mgmt_queue.py $MGMT_DB_LOC/mgmt_db_queue $REL_NAME rrup failed $PBS_JOB_ID --error $res --end_time "$end_time"
fi

date
